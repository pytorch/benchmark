import os
import inspect
from pathlib import Path

timm_model_cfgs = [
    ('regnet', 'CLASSIFICATION', 'regnety_002'),
    ('resnest', 'CLASSIFICATION', 'resnest14d'),
    ('vision_transformer', 'GENERATION', 'vit_small_patch16_224'),
    ('vovnet', 'DETECTION', 'vovnet39a'),
]

init_program_template = """# Generated by gen_timm_models.py
import torch
import timm.models.{model_name}

from ...util.model import BenchmarkModel, STEP_FN
from torchbenchmark.tasks import COMPUTER_VISION
from .config import TimmConfig

class Model(BenchmarkModel):
    task = COMPUTER_VISION.{model_category}
    optimized_for_inference = True

    def __init__(self, device=None, jit=False, variant='{model_variant}', precision='float32'):
        super().__init__()
        self.device = device
        self.jit = jit
        self.model = timm.create_model(variant, pretrained=False, scriptable=True)
        self.cfg = TimmConfig(model = self.model, device = device, precision = precision)
        self.model.to(
            device=self.device,
            dtype=self.cfg.model_dtype
        )
        if device == 'cuda':
            torch.cuda.empty_cache()

        # instantiate another model for inference
        self.eval_model = timm.create_model(variant, pretrained=False, scriptable=True)
        self.eval_model.eval()
        self.eval_model.to(
            device=self.device,
            dtype=self.cfg.model_dtype
        )

        if jit:
            self.eval_model = torch.jit.script(self.eval_model)
            assert isinstance(self.eval_model, torch.jit.ScriptModule)
            self.eval_model = torch.jit.optimize_for_inference(self.eval_model)
    

    def _gen_target(self, batch_size):
        return torch.empty(
            (batch_size,) + self.cfg.target_shape,
            device=self.device, dtype=torch.long).random_(self.cfg.num_classes)

    def _step_train(self):
        with self.annotate_forward():
            output = self.model(self.cfg.example_inputs)
            if isinstance(output, tuple):
                output = output[0]
            target = self._gen_target(output.shape[0])
            loss = self.cfg.loss(output, target)

        with self.annotate_backward():
            self.cfg.optimizer.zero_grad()
            loss.backward()

        with self.annotate_optimizer():
            self.cfg.optimizer.step()

    # vision models have another model
    # instance for inference that has
    # already been optimized for inference
    def set_eval(self):
        pass

    def _step_eval(self):
        output = self.eval_model(self.cfg.infer_example_inputs)

    def get_module(self):
        return self.model, (self.cfg.example_inputs,)

    def train(self, niter=1, step_fn: STEP_FN = lambda: None):
        self.model.train()
        for _ in range(niter):
            self._step_train()
            step_fn()

    # TODO: use pretrained model weights, assuming the pretrained model is in .data/ dir
    def eval(self, niter=1, step_fn: STEP_FN = lambda: None):
        self.model.eval()
        with torch.no_grad():
            for _ in range(niter):
                self._step_eval()
                step_fn()

if __name__ == "__main__":
    for device in ['cpu', 'cuda']:
        for jit in [False, True]:
            print("Test config: device %s, JIT %s" % (device, jit))
            m = Model(device=device, jit=jit)
            m, example_inputs = m.get_module()
            m(example_inputs)
            m.train()
            m.eval()
"""

init_config_template = """# Generated by gen_timm_models.py
import torch
import torch.nn as nn
import dataclasses
from timm.optim import create_optimizer

def resolve_precision(precision: str):
    assert precision in ('amp', 'float16', 'bfloat16', 'float32')
    use_amp = False
    model_dtype = torch.float32
    data_dtype = torch.float32
    if precision == 'amp':
        use_amp = True
    elif precision == 'float16':
        model_dtype = torch.float16
        data_dtype = torch.float16
    elif precision == 'bfloat16':
        model_dtype = torch.bfloat16
        data_dtype = torch.bfloat16
    return use_amp, model_dtype, data_dtype

@dataclasses.dataclass
class OptimizerOption:
    lr: float
    opt: str
    weight_decay: float
    momentum: float

class TimmConfig:
    def _init_input(self):
        self.example_inputs = torch.randn(
            (self.batch_size,) + self.input_size, device=self.device, dtype=self.data_dtype)
        self.infer_example_inputs = torch.randn(
            (1,) + self.input_size, device=self.device, dtype=self.data_dtype)

    def __init__(self, model, device, precision):
        self.model = model
        self.device = device
        self.use_amp, self.model_dtype, self.data_dtype = resolve_precision(precision)
        # Configurations
        self.batch_size = 64
        self.num_classes = self.model.num_classes
        self.loss = nn.CrossEntropyLoss().to(self.device)
        self.target_shape = tuple()
        self.input_size = self.model.default_cfg["input_size"]
        self._init_input()
        # Default optimizer configurations borrowed from:
        # https://github.com/rwightman/pytorch-image-models/blob/779107b693010934ac87c8cecbeb65796e218488/timm/optim/optim_factory.py#L78
        opt_args = OptimizerOption(lr=1e-4, opt="sgd", weight_decay = 0.0001, momentum = 0.9)
        self.optimizer = create_optimizer(opt_args, self.model)
"""

def process_config(timm_model_cfgs):
    TIMM_MODEL_PREFIX = "timm_"
    for (model_name, model_category, model_variant) in timm_model_cfgs:
        script_dir = os.path.dirname(os.path.realpath(__file__))
        model_path = os.path.join(script_dir, f"{TIMM_MODEL_PREFIX}{model_name}")
        Path(model_path).mkdir(exist_ok=True)
        init_file = os.path.join(model_path, "__init__.py")
        config_file = os.path.join(model_path, "config.py")
        install_file = os.path.join(model_path, "install.py")
        with open(config_file, "w") as cf:
            cf.write(init_config_template.format())
        with open(init_file, "w") as init_file:
            init_file.write(init_program_template.format(model_name = model_name,
                                                         model_category = model_category,
                                                         model_variant = model_variant))
        with open(install_file, "w") as install_f:
            install_f.write("")

if __name__ == "__main__":
    process_config(timm_model_cfgs)
