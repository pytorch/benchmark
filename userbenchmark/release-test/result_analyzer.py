from pathlib import Path
import re
import functools

def is_userbenchmark_runscript(run_script_file):
    MAGIC_LINE = "# GENERATED BY userbenchmark/release-test/__init__.py. DO NOT EDIT!"
    with open(run_script_file, "r") as rsf:
        script = rsf.read()
    if MAGIC_LINE in script:
        return True
    return False

def get_run_keys(work_dir: Path):
    run_keys = []
    for subdir in filter(lambda x: x.is_dir(), work_dir.iterdir()):
        run_script_file = subdir.joinpath("run.sh")
        if run_script_file.is_file() and is_userbenchmark_runscript(run_script_file):
            run_keys.append(subdir.name)
    return run_keys

def get_workloads(run_dir: Path):
    return list(map(lambda x: x.name, filter(lambda x: x.is_dir(), run_dir.iterdir())))

def dump_result_csv(result):
    # print the csv file
    pass

def get_peak_mem(mem_log):
    pass

def analyze_workload(run_dir: Path, workload_name: str, res):
    workload_dir = run_dir.joinpath(workload_name)
    assert workload_dir.joinpath("result.log").exists() and workload_dir.joinpath("result_mem.log").exists(), \
        f"Error: missing benchmark result file result.log or result_mem.log in {workload_dir}."
    LATENCY_REGEX = "Total time elapsed: (.*) seconds."
    with open(workload_dir.joinpath("result.log"), "r") as lf:
        latency_log = lf.readlines()[-1].strip()
    with open(workload_dir.joinpath("result_mem.log"), "r") as mf:
        mem_log = mf.readlines()
    latency = re.search(LATENCY_REGEX, latency_log).groups()[0]
    res[workload_name] = {}
    res[workload_name]["latency"] = latency
    res[workload_name]["cpu_memory"], res[workload_name]["gpu_memory"]  = get_peak_mem(mem_log)
    return res

def generate_result(workload_results):
    pass

def analyze_run_key(work_dir, run_key, r):
    run_dir = work_dir.joinpath(run_key)
    workloads = get_workloads(run_dir)
    print(workloads)
    workload_results = functools.reduce(lambda r, w: analyze_workload(run_dir, w, r), workloads, {})
    r[run_key] = workload_results
    return r

def analyze(work_dir: Path):
    # get base_args (directory starting with "pytorch-")
    work_dir = Path(work_dir)
    run_keys = get_run_keys(work_dir)
    workload_results = functools.reduce(lambda r, k: analyze_run_key(work_dir, k, r), run_keys, {})
    result = generate_result(workload_results)
    # dump result to csv file
    dump_result_csv(result)
    return result