# PyTorch Benchmark Score Version 0

This file describes how we generate the PyTorch Benchmark Score Version 0. The
goal is to help users and developers understand and be able to reproduce the
score.

A complete benchmarking environment consists of three parts: the hardware
environment, the environment variables and the standard config json.

## Hardware environment

We use an [Amazon EC2 g4dn.8xlarge
instance](https://aws.amazon.com/ec2/instance-types/g4/) as a self-hosted runner
to run the benchmark configuration V0. Before running the benchmark, we do the
a few tuning of the instance to minimize performance variance.

### Disabling Hyperthreading

We disable hyperthreading on all CPUs using the following script:

```
for cpunum in $(cat /sys/devices/system/cpu/cpu*/topology/thread_siblings_list | cut -s -d, -f2- | tr ',' '\n' | sort -un)
do 
echo 0 > /sys/devices/system/cpu/cpu$cpunum/online 
done
```

### CPU Isolation

We isolate the CPU that run the benchmark by setting the following kernel parameters:

```
isolcpus=4-15,20-31 nohz_full=4-15,20-31
```

## Environment variables

All environment variables that could affect the performance score are defined in
.github/scripts/config-v0.env.

For more details, please refer to the [env file](config-v0.env).

## Standard Config JSON

The standard config JSON file is stored in
[here](config-v0.json). It is generated by 20 iterations of
repeated runs of the same benchmark setting, whose performance is manually
verified to be stable across those runs. We pick a random execution of these 20
benchmarks as the standard execution, and the standard config JSON is a summary
of it.

First, the JSON defines the models that are tested in the standard execution.
Below is the complete list of the models we test in V0:

- pytorch_mobilenet_v3
- yolov3
- Background_Matting
- attention_is_all_you_nee...
- BERT_pytorch
- fastNLP
- dlrm
- LearningToPaint
- moco
- demucs
- pytorch_struct

Second, the JSON defines that the performance score of the standard execution
is 1000. All other V0 scores are relative to it. For example, if another
benchmark execution's score is 900, it means the its performance is slower
comparing to the standard execution.

